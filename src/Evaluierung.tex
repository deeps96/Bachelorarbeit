\section{Die Genauigkeitsmessung des Extraktionsalgorithmus}
\label{sec:evaluierung}

Der entwickelte Algorithmus deckt die grundlegenden Knotentypen für die Datenextraktion, welche in
Kapitel~\ref{subsec:erstellen-von-selektoren} eingeführt wurden, ab und ist in der Lage bis zu 70 Seiten pro Sekunde
zu verarbeiten.
Wie bereits eingangs erwähnt wurde, ist die Qualität der Extraktion für den Vergleich von großer Bedeutung - doch wie
exakt ist der entwickelte Algorithmus?
Genau diese Frage wird in diesem Kapitel beantwortet, um eine grobe Aussage für das weitere Matchingverfahren zu
treffen.
Außerdem wird darauf eingegangen, wie die Parameter $SaS$ und $F$ gewählt werden sollten, um die bestmöglichen
Ergebnisse zu erzielen.

\subsection{Die Testdaten der Evaluierung}
\label{subsec:testdaten}
Sowohl für das Antrainieren der Extraktionsregeln, als auch für die Evaluierung der Ergebnisse wurden die von idealo
zur Verfügung gestellten Angebotsdaten verwendet.
Für die nachfolgenden Messungen wurden 7500 Angebote von 50 Shops genutzt.
Je Händler wurden max.\ 50 Angebote als Trainingsmenge für die Erstellung der Regeln und 100 Angebote als Testmenge für
die Evaluierung verwendet.
Die Auswahl der Shops erfolgte zufällig.
Alle nachfolgenden Messungen basieren auf einer Momentaufnahme der Angebotsdaten inklusive der verlinkten Webseiten.

Die Links wurden nicht durch die URL-Cleaner-Kom\-po\-nen\-te bereinigt, da sonst die Angebotsdaten von idealo
möglicherweise nicht mit denen von der Webseite übereinstimmen.
Damit die Trackingstatistiken der Shopbetreiber nicht stark verfälscht werden, wurden nicht mehr als insgesamt 150
Angebote je Shop heruntergeladen.
Eine nähere Analyse der Testdaten von idealo ist in der \textsc{Abbildung}~\ref{abb:testdaten} dargestellt.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9 \textwidth, trim=0 10.05cm 0 11.4cm, clip]{resources/Testdaten-Attributverteilung.pdf}
    \caption{Attributabdeckung der Testdaten von idealo}
    \label{abb:testdaten}
    \vspace{-0.25cm}
\end{figure}

Eine Analyse der gesamten Testdaten hat ergeben, dass für jedes Angebot die Angaben zum Titel, dem Preis und der SKU
existieren.
Am seltensten existieren hingegen die HAN (68\%) und die Produktbeschreibung (77\%) eines Angebots.
Das Verhältnis der fehlenden zu den vorhandenen Produktattributen der Trainingsmenge ähnelt dem Verhältnis der
Testmenge und weicht um maximal 0.88\% bei der Produkteigenschaft ``Marke'' ab.

\subsection{Die Messergebnisse}
\label{subsec:genauigkeitsmessung}

Der Algorithmus kann durch die Größe der Anlernmenge $SaS$ und dem gewählten Filterschwellwert $F$ konfiguriert werden.
Für diese Messung wurden für jeden Shop 21 verschiedene Konfigurationen getestet.
In allen Statistiken wurden die Fälle ignoriert, bei denen idealo keine Produktattribute gespeichert hat.
Für alle 50 Shops fehlen bei den neun untersuchten Produkteigenschaften der Testmenge 7,6\% der entsprechenden Werte
bei idealo.
Für diese Fälle ist es unmöglich zu entscheiden, ob die extrahierten Angebotsinformationen korrekt sind.

Die Bestimmung der Genauigkeit erfolgte durch die Anwendung aller Regelmengen auf die Testmenge.
Anschließend wurde ausgewertet, wie oft der extrahierte Wert dem von idealo entspricht.
Zudem wurde für die Bestimmung der Precision erfasst, ob der Wert leer ist.
In \textsc{Tabelle}~\ref{tab:accuracy-precision} sind die typischen Kennziffern Accuracy und Precision für die
verschiedenen Konfigurationen basierend auf den Angeboten aller Shops aufgeführt.

\begin{table}[h]
    \centering
    \begin{tabular}{ c | c c c | c c c }
        &   \multicolumn{3}{c}{\textit{Accuracy in \%}}    &   \multicolumn{3}{c}{\textit{Precision in \%}} \\
        \textbf{F\textbackslash SaS} & \textbf{10} & \textbf{20} & \textbf{50} & \textbf{10} & \textbf{20} & \textbf{50}  \\
        \hline
        \textbf{0}       &   50.59 &   50.78 &   51.07         &   72.73 &   70.81 &   69.62 \\
        \textbf{0.5}     &   52.12 &   53.50 &   \textbf{53.98}&   88.66 &   90.39 &   91.22 \\
        \textbf{0.6}     &   51.87 &   53.07 &   53.15         &   94.15 &   94.03 &   94.93 \\
        \textbf{0.7}     &   50.15 &   51.37 &   52.02         &   96.15 &   96.39 &   95.86 \\
        \textbf{0.8}     &   47.92 &   49.69 &   50.05         &   97.84 &   97.81 &   97.76 \\
        \textbf{0.9}     &   44.61 &   46.92 &   46.57         &   98.16 &   98.14 &   98.42 \\
        \textbf{1.0}     &   41.48 &   39.27 &   36.00         &   98.17 &   97.64 &   \textbf{98.90}

    \end{tabular}
    \caption{Accuracy und Precision bei unterschiedlichen Konfigurationen unter Berücksichtigung der gesamten
    Angebotsmenge aller Shops}
    \label{tab:accuracy-precision}
    \vspace{-0.25cm}
\end{table}

Die Accuracy gibt an, wie oft ein Produktattribut in Bezug auf alle Angebote der Testmenge extrahiert wurde.
Die Precision ist etwas feingranularer und rechnet die Fälle raus, bei denen explizit nichts gefunden wurde.
Je präziser die Ergebnisse des Parsers, desto einfacher ist der ähnlichkeitsbasierte Vergleich der Matcher-Komponente.
Obwohl eine möglichst hohe Precision wichtig ist, muss eine gute Balance zwischen Accuracy und Precision gefunden
werden, damit genügend Produktattribute extrahiert werden.
Die für unseren Anwendungsfall besten Ergebnisse werden somit für die Parameter $SaS = 50$ und $F= 0.6$ erreicht.
Bei der gewählten Konfiguration gibt der Parser zwar nur in der Hälfte der Fälle einen Wert zurück, wenn jedoch ein
extrahiertes Produktattribut zurückgegeben wird, so ist dies fast immer richtig.

Um eine genauere Aussage zur Precision treffen zu können, wurden alle Nichtübereinstimmungen gesammelt und deren
Levenshtein-Distanz zum erwarteten Wert von idealo berechnet.
Ca. die Hälfte der Nichtübereinstimmungen weisen eine Levenshtein-Distanz $\leq 3$ zum erwarteten Wert von idealo
auf und sind somit ähnlich.
In Tabelle~\ref{tab:levenshtein-examples} sind Beispiele für solche Nichtübereinstimmungen gegeben.

\begin{table}[h]
    \centering
    \begin{tabular}{ p{2.75cm} | p{4.5cm} | p{4.5cm} | r}
        \textbf{Produkt-eigenschaft} & \textbf{extrahierter Wert} & \textbf{erwarteter Wert} &
        \textbf{Distanz} \\
        \hline
        TITLE & KENZO LELIXIR & KENZO L'ELIXIR & 1\\
        PRICE & 22642 & 22644 & 1\\
        DESCRIPTION & Objektiv, für Canon; EF	& Objektiv, für Canon, EF & 1\\
        BRAND &	kuechenprofi & Küchenprofi & 2\\
        BRAND & jack-wolfskin & Jack Wolfskin & 3\\
        BRAND & allcare & All Care & 3
    \end{tabular}
    \caption{Nichtübereinstimmungen, welche eine Levenshtein-Distanz $\leq 3$ besitzen}
    \label{tab:levenshtein-examples}
    \vspace{-0.25cm}
\end{table}

Der Tabelle kann man entnehmen, dass oftmals Kodierungsfehler oder unterschiedliche Trennzeichen eine
Übereinstimmung verhinderten.
Außerdem war es häufiger der Fall, dass der Preis um wenige Centbeträge von der Momentaufnahme der idealo-Daten
abwich.

Eine nähere Betrachtung der Kennziffern je Attribut liefert \textsc{Abbildung}~\ref{abb:accuracy-precision-chart}.
Wie erwartet, wird die Produktbeschreibung und die Kategorie selten extrahiert.
Dies hängt damit zusammen, dass diese Informationen am stärksten von idealo verändert werden.
Interessanterweise wird die HAN ebenfalls selten extrahiert, was mit dem häufigen Fehlen der HAN in den
Testdaten zusammenhängt.
Die in der Bild-URL enthaltene ID und die Marke werden häufig gefunden und könnten somit nützliche Features
für den maschinenlernbasierten Vergleich des Matchers sein.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{resources/accuracy-and-precision-per-attribute.PNG}
    \caption{Accuracy (links) und Precision (rechts) pro Attribut für $SaS=50$}
    \label{abb:accuracy-precision-chart}
    \vspace{-0.25cm}
\end{figure}

Zu guter letzt kann man dem Diagramm entnehmen, dass der Filterschwellwert ein gutes Mittel ist, um die Accuracy und
Precision zu beeinflussen und ein höherer SaS-Wert tendenziell besser ist.
Je höher der SaS-Wert gewählt wird, desto höher ist die Accuracy und Precision.
Mit zunehmenden Filter-Schwellwert $F$ sinkt die Accuracy, jedoch steigt dafür die Precision der extrahierten Attribute.

In der \textsc{Abbildung}~\ref{abb:accuracy-precision-box-plot} ist für die gewählten Parameter $SaS=50$ und $F=0.6$
die Streuung der Accuracy und Precision abgebildet.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{resources/accuracy-and-precision-box-plots.png}
    \caption{Accuracy (links) und Precision (rechts) pro Attribut für $SaS=50$ und $F=0.6$}
    \label{abb:accuracy-precision-box-plot}
    \vspace{-0.25cm}
\end{figure}

Den Diagrammen kann man zum einem entnehmen, dass es zwar einige Ausreißer gibt, zum anderen wird noch einmal
deutlich, dass die Marke, der Bildlink sowie die SKU häufig und genau extrahiert werden.
Die Shops, welche stark vom angezeigten Median abweichen, könnten ein guter Anhaltspunkt für zukünftige Verbesserungen
der Parser-Komponente sein.

\subsection{Mögliche Fehlerquellen der Messungen}
\label{subsec:fehlerquellen}

Die getroffenen Annahme, dass die idealo-Daten nicht von denen der Shops abweichen, trifft in der realen Welt nicht zu.
Die Angebotsdaten werden von idealo teilweise manuell oder durch Normalisierungsprozesse verändert.
Dadurch können zum Beispiel korrekt extrahierte Produktattribute fälschlicherweise als inkorrekt markiert werden.
Außerdem wird durch wird die Abweichungen die Regelgenerierung erschwert.