\section{Der Einstieg in die Welt der Preisvergleichsportale}
\label{sec:einleitung-1}

%Quellen:
%#1 https://de.statista.com/statistik/daten/studie/2054/umfrage/anteil-der-online-kaeufer-in-deutschland/
%#2 https://www.bizkanal.de/thema/online-handel-stellenwert-moeglichkeiten-und-vorteile.html
%#3 https://de.wikipedia.org/wiki/Steinzeit#Tausch_und_Handel
%#4 https://de.wikipedia.org/wiki/Internet#1969%E2%80%931983_Vorl%C3%A4ufer_Arpanet
%#5 https://de.statista.com/statistik/studie/id/23510/dokument/e-commerce-in-europa-statista-dossier/
%#6 https://de.wikipedia.org/wiki/Amazon.com
%#7 https://de.wikipedia.org/wiki/EBay
%#8 https://disq.de/2014/20141004-Preissuchmaschinen.html
%#9 https://de.statista.com/statistik/studie/id/6558/dokument/produktvergleich-im-internet-statista-dossier/

Der Fernhandel ist bereits seit der Steinzeit ein wichtiger Bestandteil der Gesellschaft. 3
Mit der Erfindung des Internets 1969 4 und der zunehmenden Verbreitung passender Endgeräte, wie zum Beispiel Computer
und Smartphones, haben sich viele Unternehmen dazu entschlossen ihre angebotenen Artikel auch online zu vermarkten.
Die Anfänge machten dabei, nach ersten simpleren Bestellkatalogen, Ebay und Amazon, welche beide seit 1995 als
Verkaufsplattform existieren. 6 7\\
Laut einer Statistik von Eurostat machte im Jahr 2017 der Onlinehandel 21\% des Gesamtumsatzes deutscher Unternehmen
aus und stellt somit einen nicht unerheblichen Anteil dar. 5
Aus einer weiteren Statistik geht hervor, dass 2016 zwei drittel der Deutschen regelmäßig online einkauften. 5\\
Dies ist vermutlich auf die vielen Vorteile, wie zum Beispiel der größeren Auswahl, den meist günstigeren Preisen
sowie dem erhöhten Komfort zurückzuführen.
Obwohl es so viele Personen gibt die Online einkaufen, nutzen rund ein Drittel nicht die Möglichkeit sich weitere
Informationen zum Produkt zu holen oder den Preis zu vergleichen. 9\\
Mit Hilfe von Preisvergleichsportalen ist es möglich, zu einem bestimmten Produkt die Angebote von unterschiedlichen
Shops zu vergleichen.
Durch diesen Vergleich, soll es dem Nutzer möglich sein, unter allen Angeboten den günstigsten
Preis zu finden.

In einem von n-tv beauftragten Test, hat das Deutsche Institut für Service-Qualität mehrere Preissuchmaschinen unter
dem Aspekt des günstigsten Preises, der Preisaktualität und dem Nutzererlebnis verglichen.
Im Ergebnis hat idealo.de
den ersten Platz eingenommen, gefolgt von billiger.de und preis.de.
Bemängelt wurde jedoch, dass selbst beim besten Preisvergleich nur für die Hälfte der Produkte der günstigste Shop
angezeigt wurde.

\subsection{Das Preisvergleichsportal idealo}
\label{sec:einleitung-2}

%Quellen:
%#1 https://de.wikipedia.org/wiki/Idealo.de
%#2 https://de.wikipedia.org/wiki/Preisvergleichsportal#Technologie

Das Preisvergleichsportal idealo existiert bereits seit 2000 und wird heute von dem Mitgründer Albrecht von Sonntag
sowie Philipp Peitsch und Jörn Rehse geführt. 1
Das Unternehmen hat seinen Sitz in Berlin-Kreuzberg und beschäftigt rund 700 Mitarbeiter.\\
Um die für den Preisvergleich erforderlichen Daten zu erhalten, hat idealo viele Verträge mit Onlineshops, welche
sich verpflichten Daten zu ihren Angeboten an idealo zu übermitteln und zu aktualisieren.
Dies ist für Preisvergleichsportale eine übliches Vorgehen. 2\\
Für jeden vermittelten Kauf erhält idealo dabei von den Shops eine kleine Provision, die auf CPC (Kosten pro Klick)
oder CPO (Kosten pro tatsächlicher Bestellung) basiert.

In der Zukunft möchte idealo die Funktion des Sofortkaufs ausbauen.
Dabei übernimmt idealo die Kommunikation mit dem Kunden und überwacht den Kaufprozess.
Somit ermöglicht es idealo auch kleinen Shops, welche sich keinen Kundensupport leisten können, eine
zufriedenstellende Abwicklung mit den Kunden zu gewährleisten.
Dies soll zum Einen das Vertrauensproblem von Kunden und unbekannteren, kleineren Shops lösen und zum Anderen den
Einkaufsprozess noch weiter vereinfachen.

\subsection{Ein Softwaresystem für den Angebotsabgleich}

Das Preisvergleichsportal idealo möchte seinen Service für den Kunden stetig verbessern.
Wie bereits erwähnt, kam bei dem Test der Preisvergleichsportale heraus, dass nur etwa 50\% der angezeigten Preise
die tatsächlich günstigsten sind.
Eine umfassendere Analyse, welche einen detaillierteren Überblick über den aktuellen Markt gibt, ist jedoch sehr
schwierig. \\
Im Rahmen des Bachelorprojektes geht es darum, idealo einen besseren Einblick darüber zu geben, welche Angebote sich
in ihrem Bestand befinden und welche noch fehlen. \\
Mit einem solchen Bericht, erhofft sich idealo intern Fehlerursachen für die fehlenden Angebote zu ermitteln.
Mit Hilfe dieser Informationen können sie den Angebotskatalog vervollständigen. \\
Je mehr Angebote idealo besitzt, desto besser wird der Preisvergleich, da tendenziell günstigere Angebote gefunden
werden können.

\subsection{Die Herausforderungen beim Katalogsabgleich}

Die allgemeinen Herausforderungen an das zu entwickelnde Softwaresystem sind vielseitig.
Mit ca. 5000 Shops und über zwei Millionen Angeboten in Deutschland gibt es sehr viele Daten, welche verarbeitet
werden müssen.
Eine Messung eines Shops soll in einem zeitlich akzeptablen Rahmen durchführbar und wiederholbar sein.
Zudem ist es erforderlich, dass mehrere Messungen parallel ablaufen können.\\
Die Schwierigkeiten bei der Verarbeitung der Daten liegt vor allem in der Beschaffung der Informationen von den
Shops, in der Übersetzung in ein vergleichbares Format, sowie dem Vergleich selbst.
Idealo möchte hierbei nicht das Tagesgeschäft der Shops beeinflussen und erwartet, dass dies bei der Umsetzung der
Lösung berücksichtigt wird.\\
Im Endeffekt soll es möglich sein, dass man einen Shop in das System eingeben kann und man nach absehbarer Zeit einen
Bericht erhält.
Dieser soll Informationen darüber enthalten, in welchen Kategorien wie viele Angebote in dem Produktkatalog von
idealo fehlen.

\subsection{Die zugrundeliegende Microservice-Architektur}

\begin{align}
    Grafik mit Architektur einsetzten
\end{align}

Das von uns entwickelte Softwaresystem besteht aus drei Komponenten: dem Crawler, dem Parser und dem Matcher.
Die Komponenten sind in einer Pipe-Architektur hintereinander geschaltet. \\
Als erstes erhält der Crawler vom Anwender einen Shop.
Diesen besucht er und lädt alle erreichbaren Webseiten dieses Shops herunter. \\
Der Parser nimmt die heruntergeladenen Seiten und extrahiert aus diesen die eigentlichen Angebotsinformationen und
bringt diese in ein einheitliches Format. \\
Im letzten Schritt vergleicht der Matcher die Menge der extrahierten Angebotsinformationen des Parsers mit dem
Angebotskatalog von Idealo.
Die Ergebnisse dieses Vergleichen werden anschließend für den Anwender visualisiert.

Wir haben uns dazu entschieden, dieses System basierend auf einer Microservice-Architektur zu implementieren.
Ein Microservice kapselt eine logische Einheit.
Im Gesamtsystem kommunizieren mehrere Microservices über die REST-Schnittstelle miteinander, um Daten auszutauschen.
Der Vorteil von Microservices besteht in der einfachen Skalierbarkeit und in der Verwendung von sogenannten
Load-Balancern, also einer Software welche die Last im Gesamtsystem optimal verteilt.
Durch die Verwendung von Microservices wird zudem Continious Deployment, also das kontinuierliche Integrieren der
aktuellsten Komponenten vereinfacht.

Für die Umsetzung der Microservicearchitektur und die Implementierung des Systems haben wir die Programmiersprache
Java verwendet.
Diese Entscheidung haben wir dem Wunsch von idealo entnommen, dass das System in einer VM (Virtual Machine) laufen soll.
Zudem habe ich bereits sehr gute Programmiererfahrungen mit dieser Sprache sammeln können.
Für die Microservices verwenden wir das weitverbreitete Framework Spring, welches durch die Unterstützung bei der
Entwicklung von REST-Clients und der simplen Kommunikation mit Datenbanken und Queues einen großen Mehrwert bietet.

\subsection{Die Aufgabe des Parsers}

Der Parser erhält von dem Crawler die heruntergeladenen Webseiten.
Das Ziel der Parser-Komponente ist es nun, aus diesen Webseiten die relevanten Informationen zu dem enthaltenen
Angebot zu extrahieren.
Diese extrahierten Informationen sollen anschließend an den Matcher weitergegeben werden.\\
Das Extrahieren der Informationen ist ein sehr wichtiger und kritischer Schritt, da die Genauigkeit die Ergebnisse
des Matchers und somit auch des Gesamtergebnisses stark beeinflusst.
Fehlerhafte Informationen können das Ergebnis so stark verfälschen, dass die Aussagekraft des Gesamtergebnisses des
Systems in Frage gestellt werden könnte.

\subsection{Die technischen Anforderungen an den Parser}

Das Internet ist eine riesige Datenquelle.
Es gibt sehr viele Shops, die zu jedem ihrer Angebote viele Informationen enthalten.
Leider sind diese jedoch mit unter sehr heterogen.
Jeder Shop befolgt seinen eigenen Standard und ist anders aufgebaut.
Es gibt Onlinehändler, die viele Informationen zu ihren Produkten angeben während andere wiederum eher spärliche
Auskünfte preisgeben.

Die Herausforderung der Parser-Komponente besteht hauptsächlich darin, diese heterogene Informationen in ein
homogenes, normalisierten Schema zu bringen.
Im Detail geht es darum, zu jedem Angebot den Titel, die Produktbeschreibung, den Preis, die Marke, die Kategorie,
die Produktbilder sowie weitere eindeutige Merkmale im Format von idealo zu erfassen.
Diese eindeutigen Merkmale sind zum Beispiel die standardisierte EAN (Europäische Artikelnummer), HAN (Händler
Artikelnummer) und SKU (Stock keeping unit/ eine shop-spezifische Kennung).

Da die Crawler-Komponente sehr viel Zeit benötigt um alle Seiten zu erfassen, spielt der Zeitfaktor für den Parser
keine große Rolle.
Eine schnelle Verarbeitung der Seiten ist dennoch wünschenswert.\\
Damit die Ergebnisse des Parsers als zuverlässig eingestuft werden und vom Matcher weiterverwenden werten können, ist
eine hohe Präzision und eine hohe Extraktionsrate erforderlich.

\subsection{Die Gegenüberstellung zweier grundlegender Herangehensweisen}
\label{sec:Einleitung-Gegenueberstellung}

%Quellen
%#1 https://schema.org/

Es gibt grundsätzlich zwei Herangehensweisen, wie man das Problem der Datenextraktion angehen kann.
Vordergründig geht es hierbei um die Frage, wie man aus den unterschiedlich strukturierten Shops Informationen
extrahiert.
Das Hauptproblem besteht darin, dass die Software wissen muss, an welchen Stellen sie die gewünschten
Produktattribute findet.\\
Es gibt den nicht-shop-spezifischen und den shop-spezifischen Ansatz.

Das von uns zu lösende Problem gibt es nicht zum ersten Mal.
Bereits Google hat sich mit der Thematik befasst, da es bei den Suchergebnissen bereits nähere Informationen zu den
Angeboten anzeigen möchte.
Im Zuge dessen hat Google gemeinsam mit den Suchmaschinen von Microsoft, Yahoo und Yandex den Schema.org-Standard für
die strukturierte Datenangabe im Internet entwickelt. 1
JSON-LD (W3C) und das Open-Graph-Protokoll (Facebook) sind weitere Spezifikationen, die bei der Strukturierung von
Produktdaten im Internet helfen sollen.\\
Laut einer Schätzung von idealo verwenden rund 40\% der Shops den Schema.org-Standard.\\
Zu Beginn haben wir ebenfalls erste Versuche basierend auf diesen Standards unternommen.
Leider haben wir schnell feststellen müssen, dass die Spezifikation oft nicht richtig eingehalten wurden, was die
Datenqualität stark verringert hat.
Wir haben uns deshalb gegen diesen Ansatz entschieden.

Bei dem shop-spezifischen Ansatz geht es darum, für jeden Shop gesonderte Spezifikationen zu erstellen. \\
Wir folgen der Annahme, dass jeder Shop ein CMS (Content Management System) zur Verwaltung seiner Angebote verwendet.
Des Weiteren gehen wir davon aus, dass sich durch die Verwendung eines CMS die Struktur der Angebote ähnelt und diese
erlernt werden kann.\\
Sollte ein Shop den oben genannten Spezifikationen, wie zum Beispiel Schema.org folgen, so sollte die
shop-spezifische Variante auch diese shop-unspezifischen Spezifikationen herausfinden.\\
Insgesamt erhoffen wir uns sowohl die Extraktionsrate als auch die Präzision des Parsers im Vergleich zu dem
nicht-shop-spezifischen Ansatz zu erhöhen und somit bessere Daten für das Vergleichen zu erhalten.